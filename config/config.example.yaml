# Example configuration for LLM Interactive Proxy

# Server settings
host: "0.0.0.0"
port: 8000
proxy_timeout: 120
command_prefix: "!/"

# Authentication
auth:
  disable_auth: false  # Set to true to disable API key authentication
  # NOTE: API keys should NEVER be stored in config files for security reasons
  # Instead, set them via environment variables (see README.md)
  api_keys: []  # API keys are read from environment variables only
  auth_token: null  # Optional auth token
  brute_force_protection:
    enabled: true  # Enable automatic blocking for repeated invalid API keys
    max_failed_attempts: 5  # Allow this many failures before blocking begins
    ttl_seconds: 900  # Window (seconds) for counting failures per IP
    initial_block_seconds: 30  # First block duration once threshold is exceeded
    block_multiplier: 2.0  # Each subsequent block grows by this multiplier
    max_block_seconds: 3600  # Cap the block duration to one hour

# Session management
session:
  cleanup_enabled: true
  cleanup_interval: 3600  # 1 hour
  max_age: 86400  # 1 day
  default_interactive_mode: true
  force_set_project: false
  project_dir_resolution_model: null  # Optional BACKEND:MODEL for auto-detecting project directories

  # Pytest output compression (reduces verbose test output to preserve context window)
  pytest_compression_enabled: true  # Default: true
  pytest_compression_min_lines: 30  # Only compress output with 30+ lines (default: 30)

  # Tool call reactor steering for pytest full-suite runs (requires opt-in)
  pytest_full_suite_steering_enabled: false

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  request_logging: false
  response_logging: false
  log_file: null  # Optional log file path

# Backend settings
# IMPORTANT SECURITY NOTE:
# API keys should NEVER be stored in configuration files!
# All API keys must be set via environment variables only:
# - OPENROUTER_API_KEY for OpenRouter
# - GEMINI_API_KEY for Gemini
# - ANTHROPIC_API_KEY for Anthropic
# - ZAI_API_KEY for ZAI
# - GOOGLE_CLOUD_PROJECT for Google Cloud Project ID
# See README.md and config/sample.env for examples

backends:
  default_backend: "openai"

  openai:
    # API key set via OPENROUTER_API_KEY environment variable
    api_url: null  # Optional custom API URL
    timeout: 120
    models:
      - "gpt-3.5-turbo"
      - "gpt-4"
      - "gpt-4-turbo"

  openrouter:
    # API key set via OPENROUTER_API_KEY environment variable
    api_url: "https://openrouter.ai/api/v1"
    timeout: 180

  anthropic:
    # API key set via ANTHROPIC_API_KEY environment variable
    timeout: 150

  gemini:
    # API key set via GEMINI_API_KEY environment variable
    timeout: 120

  qwen_oauth:
    # API key set via environment variables (OAuth flow)
    timeout: 120
    extra:
      # OAuth credentials configured via environment variables
      client_id: null
      client_secret: null

  zai:
    # API key set via ZAI_API_KEY environment variable
    timeout: 120

# Model-specific defaults
model_defaults:
  "gpt-4":  # Exact model name
    temperature: 0.7
  
  "openrouter:claude-3-opus":  # Backend:model format
    reasoning_effort: "high"

# Failover routes
failover_routes:
  default:
    policy: "ordered"
    elements:
      - "openai:gpt-4"
      - "openrouter:anthropic/claude-3-opus-20240229"

# Model name rewrite rules (optional)
# These rules allow you to dynamically rewrite model names before they are processed
# Rules are processed in order, and the first matching rule is applied
# model_aliases:
#   # Statically replace a specific model
#   - pattern: "^claude-3-sonnet-20240229$"
#     replacement: "gemini-cli-oauth-personal:gemini-1.5-flash"
#
#   # Dynamically replace any GPT model, keeping the version
#   - pattern: "^gpt-(.*)"
#     replacement: "openrouter:openai/gpt-\\1"
#
#   # Catch-all for any other model
#   - pattern: "^(.*)$"
#     replacement: "gemini-cli-oauth-personal:gemini-1.5-pro"

# Session configuration
session:
  # Planning phase: Route initial requests to a strong model for better planning
  planning_phase:
    enabled: false  # Set to true to enable planning phase
    strong_model: "openai:gpt-4"  # Strong model for planning (backend:model format)
    max_turns: 10  # Maximum turns before switching back to default model
    max_file_writes: 1  # Maximum file writes before switching back to default model
