# file: C:\Users\Mateusz\source\repos\llm-interactive-proxy\src\core\config\app_config.py
# hypothesis_version: 6.138.2

[120, 3600, 8000, 86400, '!/', ',', '.', '.json', '.yaml', '.yml', '0', '0.0.0.0', '120', '3600', '8000', '86400', 'ANTHROPIC_API_KEY', 'ANTHROPIC_TIMEOUT', 'API_KEYS', 'APP_HOST', 'APP_PORT', 'AUTH_TOKEN', 'COMMAND_PREFIX', 'CRITICAL', 'DEBUG', 'DISABLE_AUTH', 'ERROR', 'FORCE_SET_PROJECT', 'GEMINI_API_BASE_URL', 'GEMINI_API_KEY', 'GEMINI_TIMEOUT', 'INFO', 'LLM_BACKEND', 'LOG_FILE', 'LOG_LEVEL', 'OPENROUTER_API_KEY', 'OPENROUTER_TIMEOUT', 'PROXY_API_KEYS', 'PROXY_TIMEOUT', 'PYTEST_CURRENT_TEST', 'REQUEST_LOGGING', 'RESPONSE_LOGGING', 'SESSION_MAX_AGE', 'WARNING', 'ZAI_API_BASE_URL', 'ZAI_API_KEY', 'ZAI_TIMEOUT', 'allow', 'anthropic', 'api_key', 'api_keys', 'api_url', 'auth', 'auth_token', 'backends', 'before', 'cleanup_enabled', 'cleanup_interval', 'command_prefix', 'default_backend', 'disable_auth', 'extra', 'failover_routes', 'force_set_project', 'gemini', 'host', 'http://', 'https://', 'level', 'log_file', 'log_level', 'logging', 'max_age', 'model_defaults', 'openai', 'openrouter', 'port', 'proxy_timeout', 'request_logging', 'response_logging', 'session', 'session_max_age', 'timeout', 'true', 'w', 'zai']