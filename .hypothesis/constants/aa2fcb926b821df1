# file: C:\Users\Mateusz\source\repos\llm-interactive-proxy\src\connectors\gemini.py
# hypothesis_version: 6.138.2

[b'data: [DONE]\n\n', 1.0, 400, 500, ',', '/', ':', ';', 'Final payload: %s', 'POST', 'api_key', 'args', 'arguments', 'assistant', 'call_0', 'candidates', 'candidatesTokenCount', 'chat.completion', 'choices', 'completion_tokens', 'content', 'contents', 'created', 'data', 'data:', 'delta', 'fileData', 'fileUri', 'finishReason', 'finish_reason', 'function', 'functionCall', 'functionResponse', 'gemini', 'gemini/', 'gemini:', 'gemini_api_base_url', 'gemini_error', 'generationConfig', 'generation_config', 'id', 'index', 'inlineData', 'key_name', 'message', 'mimeType', 'model', 'models', 'models/', 'name', 'object', 'output', 'parts', 'promptTokenCount', 'prompt_tokens', 'response', 'role', 'system', 'temperature', 'text', 'text/event-stream', 'thinkingBudget', 'thinkingConfig', 'thinking_budget', 'tool', 'tool_calls', 'totalTokenCount', 'total_tokens', 'type', 'usage', 'usageMetadata', 'user', 'utf-8', 'x-goog-api-key', '{}']