"""
Hybrid Controller

Provides endpoints that use the new SOLID architecture.
"""

from __future__ import annotations

import logging
from typing import Any

from fastapi import Depends, Request, Response

from src.core.integration.bridge import get_integration_bridge
from src.core.interfaces.di import IServiceProvider
from src.core.interfaces.request_processor import IRequestProcessor

logger = logging.getLogger(__name__)


async def get_service_provider_if_available(request: Request) -> IServiceProvider:
    """Get the service provider if new architecture is available.
    
    Args:
        request: The FastAPI Request object
        
    Returns:
        The service provider
        
    Raises:
        RuntimeError: If service provider is not available
    """
    try:
        bridge = get_integration_bridge()
        provider = bridge.get_service_provider()
        if provider is None:
            raise RuntimeError("Service provider not initialized")
        return provider
    except Exception as e:
        logger.error(f"Service provider not available: {e}")
        raise RuntimeError(f"Service provider not available: {e!s}")


async def hybrid_chat_completions(
    http_request: Request,
    request_data: Any,
    service_provider: IServiceProvider = Depends(get_service_provider_if_available),
) -> Response:
    """Handle chat completions using the new SOLID architecture.
    
    Args:
        http_request: The HTTP request
        request_data: The parsed request data
        service_provider: The service provider
        
    Returns:
        The response
        
    Raises:
        RuntimeError: If request processor is not available
    """
    logger.debug("Processing request with new SOLID architecture")
    
    # Get request processor
    request_processor = service_provider.get_required_service(IRequestProcessor)  # type: ignore
    if request_processor is None:
        raise RuntimeError("Request processor not available")
    
    # Process the request
    return await request_processor.process_request(http_request, request_data)


async def hybrid_anthropic_messages(
    http_request: Request,
    request_data: Any,
    service_provider: IServiceProvider = Depends(get_service_provider_if_available),
) -> Response:
    """Handle Anthropic messages using the new SOLID architecture.
    
    Args:
        http_request: The HTTP request
        request_data: The parsed request data
        service_provider: The service provider
        
    Returns:
        The response
        
    Raises:
        RuntimeError: If request processor is not available
    """
    # Convert Anthropic request to OpenAI format
    from src.anthropic_converters import anthropic_to_openai_request
    from src.anthropic_models import AnthropicMessagesRequest
    
    anthropic_req = AnthropicMessagesRequest(**request_data)
    openai_request_data = anthropic_to_openai_request(anthropic_req)
    
    logger.debug("Processing Anthropic request with new SOLID architecture")
    
    # Get request processor
    request_processor = service_provider.get_required_service(IRequestProcessor)  # type: ignore
    if request_processor is None:
        raise RuntimeError("Request processor not available")
    
    # Process the request
    return await request_processor.process_request(http_request, openai_request_data)
